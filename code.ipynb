{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f894d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6d1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import cassio   \n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "ASTRA_DB_APPLICATION_TOKEN=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_ID=os.getenv(\"ASTRA_DB_ID\")\n",
    "GROQ_API=os.getenv(\"GROQ_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5ec67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader=PdfReader('Artificial_intelligence.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9f7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "raw_text=' '\n",
    "for i,page in enumerate(pdfreader.pages):\n",
    "    content=page.extract_text()\n",
    "    if content:\n",
    "        raw_text+=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e436ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN,database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9633a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='gemma2-9b-it',)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en\", model_kwargs={\"device\": \"cpu\"}, encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da134f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store=Cassandra(embedding=embeddings,table_name=\"qa_mini_demo\",session=None,keyspace=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d2b0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(separator='\\n',chunk_size=800,chunk_overlap=200,length_function=len)\n",
    "texts=text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75ac4ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial intelligence\\nArtificial intelligence  (AI) is the capability of computational systems  to perform tasks typically\\nassociated with human intelligence , such as learning, reasoning, proble m-solving, perception, and\\ndecision-making. It is a field of research  in computer science  that develops and studies methods and\\nsoftware  that enable machines to perceive their environment  and use learning  and intelligence  to take\\nactions that maximize their chances of achieving defined goals.[1] There is debate  over whether artificial\\nintelligence exhibits genuine intelligence  or merely simulates it by imitating human-like behaviors.[2]\\nHigh-profile applications of AI include advanced web search engines  (e.g., Google Search );',\n",
       " 'intelligence exhibits genuine intelligence  or merely simulates it by imitating human-like behaviors.[2]\\nHigh-profile applications of AI include advanced web search engines  (e.g., Google Search );\\nrecommendation systems  (used by YouTube, Amazon , and Netflix ); virtual assistants  (e.g., Google\\nAssistant , Siri, and Alexa ); autonomous vehicles  (e.g., Waymo ); generative  and creative  tools (e.g.,\\nlanguage models  and AI art); and superhuman  play and analysis in strategy games  (e.g., chess  and Go).\\nHowever , many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general\\napplications, often without being called AI because once something becomes useful enough and common\\nenough it\\'s not labeled AI anymore .\"[3][4]',\n",
       " 'applications, often without being called AI because once something becomes useful enough and common\\nenough it\\'s not labeled AI anymore .\"[3][4]\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The\\ntraditional goals of AI research include learning, reasoning , knowledge representation , planning , natural\\nlanguage processing , perception , and support for robotics .[a] To reach these goals, AI researchers have\\nadapted and integrated a wide range of techniques, including search  and mathematical optimization ,\\nformal logic , artificial neural networks , and methods based on statistics , operations research , and\\neconomics .[b] AI also draws upon psychology , linguistics , philosophy , neuroscience , and other fields.[5]',\n",
       " 'economics .[b] AI also draws upon psychology , linguistics , philosophy , neuroscience , and other fields.[5]\\nSome companies, such as OpenAI , Google DeepMind  and Meta ,[6] aim to create artificial general\\nintelligence  (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956,[7] and the field went through\\nmultiple cycles of optimism throughout its history ,[8][9] followed by periods of disappointment and loss of\\nfunding, known as AI winters .[10][11] Funding and interest vastly increased after 2012 when graphics\\nprocessing units  started being used to accelerate neural networks and deep learning  outperformed',\n",
       " \"funding, known as AI winters .[10][11] Funding and interest vastly increased after 2012 when graphics\\nprocessing units  started being used to accelerate neural networks and deep learning  outperformed\\nprevious AI techniques.[12] This growth accelerated further after 2017 with the transformer\\narchitecture .[13] In the 2020s, an ongoing period of rapid progress  in advanced generative AI became\\nknown as the AI boom . Generative AI's ability to create and modify content has led to several unintended\\nconsequences and harms, which has raised ethical concerns  about AI's long-term effects  and potential\\nexistential risks , prompting discussions about regulatory policies  to ensure the safety  and benefits of the\\ntechnology .\",\n",
       " 'existential risks , prompting discussions about regulatory policies  to ensure the safety  and benefits of the\\ntechnology .\\nThe general problem of simulating (or creating) intelligence has been broken  into subproblems. These\\nconsist of particular traits or capabilities that researchers expect an intelligent system to display . The traits\\ndescribed below have received the most attention and cover the scope of AI research.[a]GoalsAn ontology represents knowledge as a set of\\nconcepts within a domain and the relationships\\nbetween those concepts.Early researchers developed algorithms  that imitated step-by-step reasoning that humans use when they\\nsolve puzzles or make logical deductions .[14] By the late 1980s and 1990s, methods were developed for',\n",
       " 'solve puzzles or make logical deductions .[14] By the late 1980s and 1990s, methods were developed for\\ndealing with uncertain  or incomplete information, employing concepts from probability  and\\neconomics .[15]\\nMany of these algorithms are insuf ficient for solving large reasoning problems because they experience a\\n\"combinatorial explosion\": They becom e exponentially slower as the problems grow .[16] Even humans\\nrarely use the step-by-step deduction that early AI research could model. They solve most of their\\nproblems using fast, intuitive judgments.[17] Accurate and ef ficient reasoning is an unsolved problem.\\nKnowledge representation  and knowledge\\nengineering[18] allow AI programs to answer\\nquestions intelligently and make deductions about',\n",
       " 'Knowledge representation  and knowledge\\nengineering[18] allow AI programs to answer\\nquestions intelligently and make deductions about\\nreal-world facts. Formal knowledge representations\\nare used in content-based indexing and retrieval,[19]\\nscene interpretation,[20] clinical decision support,[21]\\nknowledge discovery (mining \"interesting\" and\\nactionable inferences from large databases ),[22] and\\nother areas.[23]\\nA knowledge base is a body of knowledge represented\\nin a form that can be used by a program . An ontology\\nis the set of objects, relations, concepts, and\\nproperties used by a particular domain of\\nknowledge.[24] Knowledge bases need to represent\\nthings such as objects, properties, categories, and\\nrelations between objects;[25] situations, events,',\n",
       " 'properties used by a particular domain of\\nknowledge.[24] Knowledge bases need to represent\\nthings such as objects, properties, categories, and\\nrelations between objects;[25] situations, events,\\nstates, and time;[26] causes and effects;[27] knowledge\\nabout knowledge (what we know about what other\\npeople know);[28] default reasoning  (things that humans assume are true until they are told differently and\\nwill remain true even when other facts are changing);[29] and many other aspects and domains of\\nknowledge.\\nAmong the most difficult problems in knowledge representation are the breadth of commonsense\\nknowledge  (the set of atomic facts that the average person knows is enormous);[30] and the sub-symbolic',\n",
       " 'Among the most difficult problems in knowledge representation are the breadth of commonsense\\nknowledge  (the set of atomic facts that the average person knows is enormous);[30] and the sub-symbolic\\nform of most commonsense knowledge (much of what people know is not represented as \"facts\" or\\n\"statements\" that they could express verbally).[17] There is also the difficulty of knowledge acquisition ,\\nthe problem of obtaining knowledge for AI applications.[c]\\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent  has goals or\\npreferences and takes actions to make them happen.[d][33] In automated planning , the agent has a specific\\ngoal.[34] In automated decision-making , the agent has preferencesâ€”there are some situations it wouldReasoning and problem-solving',\n",
       " 'goal.[34] In automated decision-making , the agent has preferencesâ€”there are some situations it wouldReasoning and problem-solving\\nKnowledge representation\\nPlanning and decision-makingIn supervised learning, the training data is labelled with\\nthe expected answers, while in unsupervised learning, the\\nmodel identifies patterns or structures in unlabelled data.prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to\\neach situation (called the \"utility \") that measures how much the agent prefers it. For each possible action,\\nit can calculate the \"expected utility \": the utility  of all possible outcomes of the action, weighted by the\\nprobability that the outcome will occur . It can then choose the action with the maximum expected\\nutility .[35]',\n",
       " 'probability that the outcome will occur . It can then choose the action with the maximum expected\\nutility .[35]\\nIn classical planning , the agent knows exactly what the effect of any action will be.[36] In most real-world\\nproblems, however , the agent may not be certain about the situation they are in (it is \"unknown\" or\\n\"unobservable\") and it may not know for certain what will happen after each possible action (it is not\\n\"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation\\nto see if the action worked.[37]\\nIn some problems, the agent\\'s prefere nces may be uncertain, especially if there are other agents or\\nhumans involved. These can be learned (e.g., with inverse reinforcement learning ), or the agent can seek',\n",
       " 'humans involved. These can be learned (e.g., with inverse reinforcement learning ), or the agent can seek\\ninformation to improve its preferences.[38] Information value theory  can be used to weigh the value of\\nexploratory or experimental actions.[39] The space of possible future actions and situations is typically\\nintractably  large, so the agents must take actions and evaluate situations while being uncertain of what the\\noutcome will be.\\nA Markov decision process  has a transition model  that describes the probability that a particular action\\nwill change the state in a particular way and a reward function that supplies the utility of each state and\\nthe cost of each action. A policy  associates a decision with each possible state. The policy could be',\n",
       " 'the cost of each action. A policy  associates a decision with each possible state. The policy could be\\ncalculated (e.g., by iteration ), be heuristic , or it can be learned.[40]\\nGame theory  describes the rational behavior of multiple interacting agents and is used in AI programs that\\nmake decisions that involve other agents.[41]\\nMachine learning  is the study of programs that can improve their performance on a given task\\nautomatically .[42] It has been a part of AI from the beginning.[e]\\nThere are several kinds of machine learning.\\nUnsupervised learning  analyzes a stream of\\ndata and finds patterns and makes predictions\\nwithout any other guidance.[45] Supervised\\nlearning  requires labeling the training data\\nwith the expected answers, and comes in two',\n",
       " 'data and finds patterns and makes predictions\\nwithout any other guidance.[45] Supervised\\nlearning  requires labeling the training data\\nwith the expected answers, and comes in two\\nmain varieties: classification  (where the\\nprogram must learn to predict what category\\nthe input belongs in) and regression  (where\\nthe program must deduce a numeric function\\nbased on numeric input).[46]\\nIn reinforcement learning , the agent is\\nrewarded for good responses and punished for bad ones. The agent learns to choose responses that are\\nclassified as \"good\".[47] Transfer learning  is when the knowledge gained from one problem is applied to aLearningKismet, a robot head which was made in\\nthe 1990s; it is a machine that can',\n",
       " 'classified as \"good\".[47] Transfer learning  is when the knowledge gained from one problem is applied to aLearningKismet, a robot head which was made in\\nthe 1990s; it is a machine that can\\nrecognize and simulate emotions.[65]new problem.[48] Deep learning  is a type of machine learning that runs inputs through biologically\\ninspired artificial neural networks  for all of these types of learning.[49]\\nComputational learning theory  can assess learners by computational complexity , by sample complexity\\n(how much data is required), or by other notions of optimization .[50]\\nNatural language processing  (NLP) allows programs to read, write and communicate in human\\nlanguages.[51] Specific problems include speech recognition , speech synthesis , machine translation ,',\n",
       " 'Natural language processing  (NLP) allows programs to read, write and communicate in human\\nlanguages.[51] Specific problems include speech recognition , speech synthesis , machine translation ,\\ninformation extraction , information retrieval  and question answering .[52]\\nEarly work, based on Noam Chomsky \\'s generative grammar  and semantic networks , had difficulty with\\nword-sense disambiguation[f] unless restricted to small domains called \"micro-worlds \" (due to the\\ncommon sense knowledge problem[30]). Margaret Masterman  believed that it was meaning and not\\ngrammar that was the key to understanding languages, and that thesauri  and not dictionaries should be the\\nbasis of computational language structure.',\n",
       " 'grammar that was the key to understanding languages, and that thesauri  and not dictionaries should be the\\nbasis of computational language structure.\\nModern deep learning techniques for NLP include word embedding  (representing words, typically as\\nvectors  encoding their meaning),[53] transformers  (a deep learning architecture using an attention\\nmechanism),[54] and others.[55] In 2019, generative pre-trained transformer  (or \"GPT\") language models\\nbegan to generate coherent text,[56][57] and by 2023, these models were able to get human-level scores on\\nthe bar exam , SAT test, GRE  test, and many other real-world applications.[58]\\nMachine perception  is the ability to use input from sensors (such as cameras, microphones, wireless',\n",
       " 'the bar exam , SAT test, GRE  test, and many other real-world applications.[58]\\nMachine perception  is the ability to use input from sensors (such as cameras, microphones, wireless\\nsignals, active lidar, sonar , radar , and tactile sensors ) to deduce aspects of the world. Computer vision  is\\nthe ability to analyze visual input.[59]\\nThe field includes speech recognition ,[60] image classification ,[61] facial recognition , object\\nrecognition ,[62] object tracking ,[63] and robotic perception .[64]\\nAffective computing  is a field that comprises systems that\\nrecognize, interpret, process, or simulate human feeling,\\nemotion, and mood .[66] For example, some virtual assistants\\nare programmed to speak conversationally or even to banter\\nhumorously; it makes them appear more sensitive to the',\n",
       " 'emotion, and mood .[66] For example, some virtual assistants\\nare programmed to speak conversationally or even to banter\\nhumorously; it makes them appear more sensitive to the\\nemotional dynamics of human interaction, or to otherwise\\nfacilitate humanâ€“computer interaction .\\nHowever , this tends to give naÃ¯ve users an unrealistic\\nconception of the intelligence of existing  computer agents.[67]\\nModerate successes related to affective computing includeNatural language processing\\nPerception\\nSocial intelligencetextual sentiment analysis  and, more recently , multimodal sentiment analysis , wherein AI classifies the\\neffects displayed by a videotaped subject.[68]\\nA machine with artificial general intelligence  would be able to solve a wide variety of problems with',\n",
       " 'effects displayed by a videotaped subject.[68]\\nA machine with artificial general intelligence  would be able to solve a wide variety of problems with\\nbreadth and versatility similar to human intelligence .[69]\\nAI research uses a wide variety of techniques to accomplish the goals above.[b]\\nAI can solve many problems by intelligently searching through many possible solutions.[70] There are\\ntwo very dif ferent kinds of search used in AI: state space search  and local search .\\nState space search  searches through a tree of possible states to try to find a goal state.[71] For example,\\nplanning  algorithms search through trees of goals and subgoals, attempting to find a path to a target goal,\\na process called means-ends analysis .[72]',\n",
       " 'planning  algorithms search through trees of goals and subgoals, attempting to find a path to a target goal,\\na process called means-ends analysis .[72]\\nSimple exhaustive searches[73] are rarely sufficient for most real-world problems: the search space  (the\\nnumber of places to search) quickly grows to astronomical numbers . The result is a search that is too slow\\nor never completes.[16] \"Heuristics \" or \"rules of thumb\" can help prioritize choices that are more likely to\\nreach a goal.[74]\\nAdversarial search  is used for game-playing  programs, such as chess or Go. It searches through a tree of\\npossible moves and countermoves, looking for a winning position.[75]\\nLocal search  uses mathematical optimization  to find a solution to a problem. It begin s with some form of',\n",
       " 'possible moves and countermoves, looking for a winning position.[75]\\nLocal search  uses mathematical optimization  to find a solution to a problem. It begin s with some form of\\nguess and refines it incrementally .[76]\\nGradient descent  is a type of local search that optimizes a set of numerical parameters by incrementally\\nadjusting them to minimize a loss function . Variants of gradient descent are commonly used to train\\nneural networks ,[77] through the backpropagation  algorithm.\\nAnother type of local search is evolutionary computation , which aims to iteratively improve a set of\\ncandidate solutions by \"mutating\" and \"recombining\" them, selecting  only the fittest to survive each\\ngeneration.[78]',\n",
       " 'candidate solutions by \"mutating\" and \"recombining\" them, selecting  only the fittest to survive each\\ngeneration.[78]\\nDistributed search processes can coordinate via swarm intelligence  algorithms. Two popular swarm\\nalgorithms used in search are particle swarm optimization  (inspired by bird flocking ) and ant colony\\noptimization  (inspired by ant trails ).[79]General intelligence\\nTechniques\\nSearch and optimization\\nState space search\\nLocal searchIllustration of gradient descent for 3\\ndifferent starting points; two parameters\\n(represented by the plan coordinates) are\\nadjusted in order to minimize the loss\\nfunction (the height)Formal logic  is used for reasoning  and knowledge\\nrepresentation .[80] Formal logic comes in two main forms:',\n",
       " 'adjusted in order to minimize the loss\\nfunction (the height)Formal logic  is used for reasoning  and knowledge\\nrepresentation .[80] Formal logic comes in two main forms:\\npropositional logic  (which operates on statements that are true\\nor false and uses logical connectives  such as \"and\", \"or\",\\n\"not\" and \"implies\")[81] and predicate logic  (which also\\noperates on objects, predicates and relations and uses\\nquantifiers  such as \"Every  X is a Y\" and \"There are some  Xs\\nthat are Ys\").[82]\\nDeductive reasoning  in logic is the process of proving  a new\\nstatement (conclusion ) from other statements that are given\\nand assumed to be true (the premises ).[83] Proofs can be\\nstructured as proof trees , in which nodes are labelled by\\nsentences, and children nodes are connected to parent nodes',\n",
       " 'and assumed to be true (the premises ).[83] Proofs can be\\nstructured as proof trees , in which nodes are labelled by\\nsentences, and children nodes are connected to parent nodes\\nby inference rules .\\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root\\nnode is labelled by a solution of the problem and whose leaf nodes  are labelled by premises or axioms . In\\nthe case of Horn clauses , problem-solving search can be performed by reasoning forwards  from the\\npremises or backwards  from the problem.[84] In the more general case of the clausal form of first-order\\nlogic , resolution  is a single, axiom-free rule of inferen ce, in which a problem is solved by proving a',\n",
       " 'logic , resolution  is a single, axiom-free rule of inferen ce, in which a problem is solved by proving a\\ncontradiction from premises that include the negation of the problem to be solved.[85]\\nInference in both Horn clause logic and first-order logic is undecidable , and therefore intractable .\\nHowever , backward reasoning with Horn clauses, which underpins computation in the logic\\nprogramming  language Prolog , is Turing complete . Moreover , its efficiency is compet itive with\\ncomputation in other symbolic programming  languages.[86]\\nFuzzy logic  assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are\\nvague and partially true.[87]\\nNon-monotonic logics , including logic programming with negation as failure , are designed to handle',\n",
       " 'vague and partially true.[87]\\nNon-monotonic logics , including logic programming with negation as failure , are designed to handle\\ndefault reasoning .[29] Other specialized versions of logic have been developed to describe many complex\\ndomains.\\nMany problems in AI (including reasoni ng, planning, learning, perception, and robotics) require the agent\\nto operate with incomplete or uncertain information. AI researchers have devised a number of tools to\\nsolve these problems using methods from probability  theory and economics.[88] Precise mathematical\\ntools have been developed that analyze how an agent can make choices and plan, using decision theory ,\\ndecision analysis ,[89] and information value theory .[90] These tools include models such as Markov',\n",
       " 'decision analysis ,[89] and information value theory .[90] These tools include models such as Markov\\ndecision processes ,[91] dynamic decision networks ,[92] game theory  and mechanism design .[93]Logic\\nProbabilistic methods for uncertain reasoningA simple Bayesian network, with the associated conditional probability\\ntables\\nExpectationâ€“maximization clustering of Old\\nFaithful eruption data starts from a random guess\\nbut then successfully converges on an accurate\\nclustering of the two physically distinct modes of\\neruption.Bayesian networks[94] are a tool\\nthat can be used for reasoning\\n(using the Bayesian inference\\nalgorithm),[g][96] learning  (using\\nthe expectationâ€“maximization\\nalgorithm ),[h][98] planning  (using\\ndecision networks )[99] and\\nperception  (using dynamic',\n",
       " '(using the Bayesian inference\\nalgorithm),[g][96] learning  (using\\nthe expectationâ€“maximization\\nalgorithm ),[h][98] planning  (using\\ndecision networks )[99] and\\nperception  (using dynamic\\nBayesian networks ).[92]\\nProbabilistic algorithms can also\\nbe used for filtering, prediction,\\nsmoothing, and finding\\nexplanations for streams of data,\\nthus helping perception systems\\nanalyze processes that occur over\\ntime (e.g., hidden Markov models  or Kalman filters ).[92]\\nThe simplest AI applications can be divided into two\\ntypes: classifiers (e.g., \"if shiny then diamond\"), on\\none hand, and controllers (e.g., \"if diamond then pick\\nup\"), on the other hand. Classifiers[100] are functions\\nthat use pattern matching  to determine the closest\\nmatch. They can be fine-tuned based on chosen',\n",
       " 'up\"), on the other hand. Classifiers[100] are functions\\nthat use pattern matching  to determine the closest\\nmatch. They can be fine-tuned based on chosen\\nexamples using supervised learning . Each pattern\\n(also called an \"observation \") is labeled with a certain\\npredefined class. All the observations combined with\\ntheir class labels are known as a data set. When a new\\nobservation is received, that observation is classified\\nbased on previous experience.[46]\\nThere are many kinds of classifiers in use.[101] The\\ndecision tree is the simplest and most widely used\\nsymbolic machine learning algorithm.[102] K-nearest\\nneighbor  algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods',\n",
       " 'symbolic machine learning algorithm.[102] K-nearest\\nneighbor  algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods\\nsuch as the support vector machine  (SVM) displaced k-nearest neighbor in the 1990s.[103] The naive\\nBayes classifier  is reportedly the \"most widely used learner\"[104] at Google, due in part to its\\nscalability .[105] Neural networks  are also used as classifiers.[106]\\nAn artificial neural network is based on a collection of nodes also known as artificial neurons , which\\nloosely model the neurons  in a biological brain. It is trained to recognise patterns; once trained, it can\\nrecognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output.Classifiers and statistical learning\\nmethods',\n",
       " 'recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output.Classifiers and statistical learning\\nmethods\\nArtificial neural networksA neural network is an interconnected\\ngroup of nodes, akin to the vast network\\nof neurons in the human brain.\\nDeep learning is a subset of\\nmachine learning, which is\\nitself a subset of artificial\\nintelligence.[114]Each node applies a function and once the weight  crosses its\\nspecified threshold, the data is transmitted to the next layer . A\\nnetwork is typically called a deep neural network if it has at\\nleast 2 hidden layers.[106]\\nLearning algorithms for neural networks use local search  to\\nchoose the weights that will get the right output for each input\\nduring training. The most common training technique is the',\n",
       " 'Learning algorithms for neural networks use local search  to\\nchoose the weights that will get the right output for each input\\nduring training. The most common training technique is the\\nbackpropagation  algorithm.[107] Neural networks learn to\\nmodel complex relationships between inputs and outputs and\\nfind patterns  in data. In theory , a neural network can learn any\\nfunction.[108]\\nIn feedforward neural networks  the signal passes in only one\\ndirection.[109] The term perceptron  typically refers to a single-\\nlayer neural network.[110] In contrast, deep learning uses\\nmany layers.[111] Recurrent neural networks  (RNNs) feed the output signal back into the input, which\\nallows short-term memories of previous input events. Long short-term memory  networks (LSTMs) are',\n",
       " \"many layers.[111] Recurrent neural networks  (RNNs) feed the output signal back into the input, which\\nallows short-term memories of previous input events. Long short-term memory  networks (LSTMs) are\\nrecurrent neural networks that better preserve longterm dependencies and are less sensitive to the\\nvanishing gradient problem .[112] Convolutional neural networks  (CNNs) use layers of kernels  to more\\nefficiently process local patterns. This local processing is especially important in image processing , where\\nthe early CNN layers typically identify simple local patterns such as edges and curves, with subsequent\\nlayers detecting more complex patterns like textures, and eventually whole objects.[113]\\nDeep learning  uses several layers of neurons between the network's\",\n",
       " \"layers detecting more complex patterns like textures, and eventually whole objects.[113]\\nDeep learning  uses several layers of neurons between the network's\\ninputs and outputs.[111] The multiple layers can progressively extract\\nhigher -level features from the raw input. For example, in image\\nprocessing , lower layers may identify edges, while higher layers may\\nidentify the concepts relevant to a human such as digits, letters, or\\nfaces.[115]\\nDeep learning has profoundly improved the performance of programs\\nin many important subfields of artificial intelligence, including\\ncomputer vision , speech recognition , natural language processing ,\\nimage classification ,[116] and others. The reason that deep learning\\nperforms so well in so many applications is not known as of 2021.[117]\",\n",
       " 'image classification ,[116] and others. The reason that deep learning\\nperforms so well in so many applications is not known as of 2021.[117]\\nThe sudden success of deep learning in 2012â€“2015 did not occur\\nbecause of some new discovery or theoretical breakthrough (deep\\nneural networks and backpropagation had been described by many\\npeople, as far back as the 1950s)[i] but because of two factors: the incredib le increase in computer power\\n(including the hundred-fold increase in speed by switching to GPUs ) and the availability of vast amounts\\nof training data, especially the giant curated datasets  used for benchmark testing, such as ImageNet .[j]Deep learningGenerative pre-trained transformers  (GPT) are large language models  (LLMs) that generate text based on',\n",
       " 'the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large\\ncorpus of text that can be from the Internet. The pretraining consists of predicting the next token  (a token\\nbeing usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate\\nknowledge about the world and can then generate human-like text by repeatedly predicting the next\\ntoken. Typically , a subsequent training phase makes the model more truthful, useful, and harmless,\\nusually with a technique called reinforcement learning from human feedback  (RLHF). Current GPT\\nmodels are prone to generating falsehoo ds called \"hallucinations \". These can be reduced with RLHF and',\n",
       " 'usually with a technique called reinforcement learning from human feedback  (RLHF). Current GPT\\nmodels are prone to generating falsehoo ds called \"hallucinations \". These can be reduced with RLHF and\\nquality data, but the problem has been getting worse for reasoning systems.[125] Such systems are used in\\nchatbots , which allow people to ask a question or request a task in simple text.[126][127]\\nCurrent models and services include ChatGPT , Claude , Gemini , Copilot , and Meta AI.[128] Multimodal\\nGPT models can process dif ferent types of data ( modalities ) such as images, videos, sound, and text.[129]\\nIn the late 2010s, graphics processing units  (GPUs) that were increasingly designed with AI-specific',\n",
       " \"In the late 2010s, graphics processing units  (GPUs) that were increasingly designed with AI-specific\\nenhancements and used with specialized TensorFlow  software had replaced previously used central\\nprocessing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine\\nlearning  models' training.[130] Specialized programming languages  such as Prolog  were used in early AI\\nresearch,[131] but general-purpose programming languages  like Python  have become predominant.[132]\\nThe transistor density in integrated circuits  has been observed to roughly double every 18 monthsâ€”a\\ntrend known as Moore's law, named after the Intel co-founder Gordon Moore , who first identified it.\",\n",
       " \"trend known as Moore's law, named after the Intel co-founder Gordon Moore , who first identified it.\\nImprovements in GPUs  have been even faster ,[133] a trend sometimes called Huang's law,[134] named\\nafter Nvidia  co-founder and CEO Jensen Huang .\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including:\\nsearch engines  (such as Google Search ), targeting online advertisements , recommendation systems\\n(offered by Netflix , YouTube or Amazon ), driving internet traffic, targeted advertising  (AdSense ,\\nFacebook ), virtual assistants  (such as Siri or Alexa ), autonomous vehicles  (including drones , ADAS  and\\nself-driving cars), automatic language translation  (Microsoft Translator , Google Translate ), facial\",\n",
       " \"self-driving cars), automatic language translation  (Microsoft Translator , Google Translate ), facial\\nrecognition  (Apple 's FaceID  or Microsoft 's DeepFace  and Google 's FaceNet ) and image labeling  (used by\\nFacebook , Apple's Photos  and TikTok). The deployment of AI may be overs een by a chief automation\\nofficer (CAO).\\nThe application of AI in medicine  and medical research  has the potential to increase patient care and\\nquality of life.[135] Through the lens of the Hippocratic Oath , medical professionals are ethically\\ncompelled to use AI, if applications can more accurately diagnose and treat patients.[136][137]GPT\\nHardware and software\\nApplications\\nHealth and medicineFor medical research, AI is an important tool for processing and integrating big data. This is particularly\",\n",
       " 'Hardware and software\\nApplications\\nHealth and medicineFor medical research, AI is an important tool for processing and integrating big data. This is particularly\\nimportant for organoid  and tissue engineering  development which use microscopy  imaging as a key\\ntechnique in fabrication.[138] It has been suggested that AI can overcome discrepancies in funding\\nallocated to different fields of research.[138][139] New AI tools can deepen the understanding of\\nbiomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to\\napproximate, in hours rather than month s, the 3D structure of a protein .[140] In 2023, it was reported that\\nAI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-',\n",
       " \"AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-\\nresistant bacteria.[141] In 2024, researchers used machine learning to accelerate the search for Parkinson's\\ndisease  drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of\\nalpha-synuclein  (the protein that characterises Parkinson's disease). They were able to speed up the initial\\nscreening process ten-fold and reduce the cost by a thousand-fold.[142][143]\\nGame playing  programs have been used since the 1950s to demonstrate and test AI's most advanced\\ntechniques.[144] Deep Blue  became the first computer chess-playing  system to beat a reigning world chess\",\n",
       " \"techniques.[144] Deep Blue  became the first computer chess-playing  system to beat a reigning world chess\\nchampion, Garry Kasparov , on 11 May 1997.[145] In 2011, in a Jeopar dy! quiz show  exhibition match,\\nIBM 's question answering system , Watson , defeated the two greatest Jeopar dy! champions, Brad Rutter\\nand Ken Jennings , by a significant margin.[146] In March 2016, AlphaGo  won 4 out of 5 games of Go in a\\nmatch with Go champion Lee Sedol , becoming the first computer Go-playing system to beat a\\nprofessional Go player without handicaps . Then, in 2017, it defeated Ke Jie, who was the best Go player\\nin the world.[147] Other programs handle imperfect-information  games, such as the poker -playing\",\n",
       " \"in the world.[147] Other programs handle imperfect-information  games, such as the poker -playing\\nprogram Pluribus .[148] DeepMind  developed increasingly generalistic reinforcement learning  models,\\nsuch as with MuZero , which could be trained to play chess, Go, or Atari  games.[149] In 2019, DeepMind's\\nAlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game\\nthat involves incomplete knowledge of what happens on the map.[150] In 2021, an AI agent competed in a\\nPlayStation Gran Turismo  competition, winning against four of the world's best Gran Turismo drivers\\nusing deep reinforcement learning.[151] In 2024, Google DeepMind introduced SIMA, a type of AI\",\n",
       " \"PlayStation Gran Turismo  competition, winning against four of the world's best Gran Turismo drivers\\nusing deep reinforcement learning.[151] In 2024, Google DeepMind introduced SIMA, a type of AI\\ncapable of autonomously playing nine previously unseen open-world  video games by observing screen\\noutput, as well as executing short, specific tasks in response to natural language instructions.[152]\\nLarge language models, such as GPT-4, Gemini , Claude , Llama  or Mistral , are increasingly used in\\nmathematics. These probabilistic models  are versatile, but can also produce wrong answers in the form of\\nhallucinations . They sometimes need a large database of mathematical problems to learn from, but also\",\n",
       " 'hallucinations . They sometimes need a large database of mathematical problems to learn from, but also\\nmethods such as supervised  fine-tuning[153] or trained classifiers  with human-annotated data to improve\\nanswers for new problems and learn from corrections.[154] A February 2024 study showed that the\\nperformance of some language models for reasoning capabilities in solving math problems not included\\nin their training data was low, even for problems with only minor deviations from trained data.[155] One\\ntechnique to improve their performance involves training the models to produc e correct reasoning  steps,\\nrather than just the correct result.[156] The Alibaba Group  developed a version of its Qwen  models called',\n",
       " 'rather than just the correct result.[156] The Alibaba Group  developed a version of its Qwen  models called\\nQwen2-Math , that achieved state-of-the-art performance on several mathematical benchmarks, including\\n84% accuracy on the MATH dataset of competition mathematics problem s.[157] In January 2025,Games\\nMathematicsMicrosoft proposed the technique rStar -Math  that leverages Monte Carlo tree search  and step-by-step\\nreasoning, enabling a relatively small language model like Qwen-7B  to solve 53% of the AIME  2024 and\\n90% of the MA TH benchmark problems.[158]\\nAlternatively , dedicated models for mathematical problem solving with higher precision for the outcome\\nincluding proof of theorems have been developed such as AlphaT ensor , AlphaGeometry , AlphaPr oof and',\n",
       " 'including proof of theorems have been developed such as AlphaT ensor , AlphaGeometry , AlphaPr oof and\\nAlphaEvolve[159] all from Google DeepMind ,[160] Llemma  from EleutherAI[161] or Julius .[162]\\nWhen natural language is used to describe mathematical problems, conver ters can transform such\\nprompts into a formal language such as Lean  to define mathematical tasks.\\nSome models have been developed to solve challenging problems and reach good results in benchmark\\ntests, others to serve as educational tools in mathematics.[163]\\nTopological deep learning  integrates various topological  approaches.\\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39312f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store.add_texts(texts[:50])\n",
    "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3425e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is AI\n",
      "ANSWER:  Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making.\n",
      "0.93,Artificial intelligence\n",
      "Artificial intelligence  (AI) is the capability of compu\n",
      "0.93,Artificial intelligence\n",
      "Artificial intelligence  (AI) is the capability of compu\n",
      "Question: Wat are core parts of AI\n",
      "ANSWER:  According to the text, what are some tools AI researchers have devised to solve problems related to incomplete or uncertain information?\n",
      "\n",
      "\n",
      "The text states that AI researchers have devised tools using methods from probability theory and economics.  It also mentions  decision theory, decision analysis, and information value theory as precise mathematical tools used for analyzing choices and planning.\n",
      "0.92,vague and partially true.[87]\n",
      "Non-monotonic logics , including logic programming\n",
      "0.92,vague and partially true.[87]\n",
      "Non-monotonic logics , including logic programming\n",
      "Question: parts of AI\n",
      "ANSWER:  What are the two simplest types of AI applications?\n",
      "\n",
      "\n",
      "According to the text, the two simplest types of AI applications are:\n",
      "\n",
      "* **Classifiers** (e.g., \"if shiny then diamond\")\n",
      "* **Controllers** (e.g., \"if diamond then pick up\")\n",
      "0.92,(using the Bayesian inference\n",
      "algorithm),[g][96] learning  (using\n",
      "the expectatio\n",
      "0.92,(using the Bayesian inference\n",
      "algorithm),[g][96] learning  (using\n",
      "the expectatio\n",
      "Question: what is the difference ebtween machine learning and AI\n",
      "ANSWER:  While this text provides information about AI concepts and algorithms, it doesn't explicitly define or compare machine learning and AI. \n",
      "\n",
      "Therefore, I cannot answer your question based on the context given.\n",
      "0.93,(using the Bayesian inference\n",
      "algorithm),[g][96] learning  (using\n",
      "the expectatio\n",
      "0.93,(using the Bayesian inference\n",
      "algorithm),[g][96] learning  (using\n",
      "the expectatio\n"
     ]
    }
   ],
   "source": [
    "F=True\n",
    "while True: \n",
    "    if F:\n",
    "        query_text=input(\"Enter text\").strip()\n",
    "    else:\n",
    "        query_text=input(\"Enter next Question\").strip()\n",
    "    if query_text.lower()=='exit':\n",
    "        break \n",
    "    if query_text == \" \":\n",
    "        continue\n",
    "    F=False\n",
    "    print('Question:',query_text)\n",
    "    answer=astra_vector_index.query(query_text,llm=llm).strip()\n",
    "    print(\"ANSWER: \",answer)\n",
    "    for doc,score in astra_vector_store.similarity_search_with_relevance_scores(query=query_text,k=2):\n",
    "        print(f\"{score:.2f},{doc.page_content[:80]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ca253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
